{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Convolutional Neural Networks\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Computers Interpret Images\n",
    "\n",
    "![cnn_1.png](images/cnn_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Cross-Entropy\n",
    "\n",
    "![cnn_2.png](images/cnn_2.png)\n",
    "\n",
    "> model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "이런 식으로 손실 함수, 최적화 옵션 등을 설정해 줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Connectivity\n",
    "\n",
    "인접한 구역은 비슷한 결과를 도출할 확률이 높다. 따라서 특정 구역을 나눠서 판단하도록 설계하는 것이 더 정확도가 높다.    \n",
    "각 구역마다의 weight와 bias를 가진다. \n",
    "\n",
    "![cnn_3.png](images/cnn_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers\n",
    "\n",
    "CNN으로 Local Connectivity를 구성할 수 있다(필터를 각 구역 별로 이동하면서 결과를 가져온다 : 필터로 특정 패턴을 찾아낸다).\n",
    "\n",
    "![cnn_4.png](images/cnn_4.png)\n",
    "\n",
    "여러 개의 필터를 사용할 수 있다.\n",
    "\n",
    "![cnn_5.png](images/cnn_5.png)\n",
    "\n",
    "컬러 이미지는 RGB 별로 가져와서 판별할 수 있다.\n",
    "\n",
    "- Dense layer : fully connected\n",
    "- Convolutional layer : localy connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride and Padding\n",
    "\n",
    "- Stride : 필터가 한 번에 얼마씩 이동하는지\n",
    "- Padding : 필터가 이미지 범위 벗어나는 것을 방지하기 위해 0으로 채워주는(결과값에 영향 주지 않는다) 영역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x1066e0898>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv2D #CNN 로드\n",
    "\n",
    "Conv2D(filters=16, kernel_size=2, strides=2, activation='relu', input_shape=(200, 200, 1)) # 첫 번째 레이어(input layer)의 경우, input_shape를 설정해 줘야 한다.\n",
    "# Conv2D(filters, kernel_size, strides, padding, activation='relu', input_shape) 로 초기화할 수 있다.\n",
    "# filters : 필터의 수, kernel_size : 필터의 높이와 너비(튜플이 될 수 있다.) #이 두가지 파라미터가 필요하며 나머지 파라미터는 optional\n",
    "# strides : 필터의 이동 간격 (default == 1)\n",
    "# padding : 'valid' or 'same' (default == same)\n",
    "# activation : 활성화 함수 default == nil\n",
    "\n",
    "# Conv2D(64, (2,2), activation='relu') 이런 식으로 선언할 수도 있다. 크기가 2x2인 64개의 필터. Relu 사용. 다른 파라미터는 기본값 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 16)      80        \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, strides=2, padding='valid', activation='relu', input_shape=(200, 200, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=2, padding='same', \n",
    "    activation='relu', input_shape=(128, 128, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling Layers in Keras\n",
    "\n",
    "CNN이 진행될 수록 depth가 늘어나는데, Pooling 으로 차원을 줄인다.\n",
    "![cnn_6.jpeg](images/cnn_6.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 15)        0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, input_shape=(100, 100, 15)))\n",
    "# MaxPooling2D(pool_size, strides, padding)\n",
    "# pool_size : 풀링 필터의 높이와 너비(튜플 가능) #이 외의 파라미터는 모두 옵셔널\n",
    "# strides : 풀링 필터의 이동 간격(튜플 가능). default는 pool_size\n",
    "# padding : 'valid' or 'same'. default는 valid\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs for Image Classification\n",
    "\n",
    "cifar10_cnn.ipynb 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 528,054\n",
      "Trainable params: 528,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten()) #마지막에는 평탄화한 후 \n",
    "model.add(Dense(500, activation='relu')) #full connected layer에 연결\n",
    "model.add(Dense(10, activation='softmax')) #판별(가지 수가 10개)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation in Keras\n",
    "\n",
    "cifar10_augmentation.ipynb 참고    \n",
    "\n",
    "오버피팅을 방지하고, 실용적인 모델을 위해 이미지가 약간 치우쳤거나 회전되었을 경우를 테스트해야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning in Keras\n",
    "\n",
    "transfer_learning.ipynb    \n",
    "bottleneck_features.ipynb    \n",
    "참고\n",
    "\n",
    "CNN은 데이터가 너무 방대하므로 이미 만들어져 있는 모델을 가져와서 추가학습을 통해 나은 모델을 만들 수 있다.    \n",
    "Transfer Learning를 사용할 때, Fully connected layer를 추가하는 것을 제외한다.    \n",
    "결국, 처음 input layer를 연결하고, 바로 Softmax로 output layer를 연결하면 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
