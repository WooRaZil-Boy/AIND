{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Planning\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite Sequences\n",
    "\n",
    "![planniing_0.png](images/planning_0.png)\n",
    "\n",
    "Stochastic Environment에서는 에이전트의 행동을 예측할 수 없으므로 행동이 보장될 때까지 루프를 사용할 수 있다. 여기서 Sucking은 제대로 작동하지만, Move는 Stochastic이라 가정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Finding a Successful Plan Question\n",
    "\n",
    "![planning_1.png](images/planning_1.png)\n",
    "\n",
    "- Unbounded Solution : 무제한 접근이 가능한 방법에서는 모든 마지막 노드는 답이 되어야 한다. 수 십번 루프를 하더라도 결국에는 답을 찾게 된다.\n",
    "- Bounded Solution : 제한적 접근이 가능한 방법에서는 루프가 없어야 한다. 루프가 있으면 횟수가 보장되지 않기 때문에 답을 찾을 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking the-Predict Update Cycle\n",
    "\n",
    "![planning_2.png](images/planning_2.png)\n",
    "\n",
    "하지만 이런 방법은 상태의 수가 많아지면 계산량이 기하급수적으로 늘어난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Planning 1\n",
    "\n",
    "![planning_3.png](images/planning_3.png)\n",
    "\n",
    "- State : Bool으로 판단 가능해야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Planning 2\n",
    "\n",
    "![planning_4.png](images/planning_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Search\n",
    "\n",
    "![planning_5.png](images/planning_5.png)\n",
    "\n",
    "- Progression Search : Initial state부터 시작해서 Goal까지 찾아가는 검색. Forward Search라고도 한다. \n",
    "- Regression Search : Goal에서 부터 시작해서 반대로. Backwards Search라고도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan Space Search\n",
    "\n",
    "![planning_6.png](images/planning_6.png)\n",
    "\n",
    "- Plan Space Search : States가 아닌 Plans으로 검색할 때 사용한다. Initial state와 Goal만 있는 Plan에서 추가적으로 필요한 Plans을 추가해 나간다.\n",
    "\n",
    "**현재는 Progression Search가 가장 흔하게 쓰인다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Puzzle Example\n",
    "\n",
    "![planning_7.png](images/planning_7.png)\n",
    "\n",
    "위와 같은 퍼즐이 있을 때, 스키마는 아래 그림과 같이 된다. 여기서 몇 개의 요소를 지울 수 있다.\n",
    "\n",
    "- Throw out a prequisite you make the problem easier\n",
    "- Number of misplaced tiles Heristic\n",
    "- Ignore negative effect you make the problem easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Situation Calculus \n",
    "\n",
    "First Order Logic으로 간결하게 정리할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
