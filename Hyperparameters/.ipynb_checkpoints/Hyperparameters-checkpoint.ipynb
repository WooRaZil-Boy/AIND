{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Hyperparameters\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "\n",
    "0.01이 가장 일반적인 laerning rate\n",
    "\n",
    "![hyperparameter_1.png](images/hyperparameter_1.png)    \n",
    "\n",
    "시간이 지날수록 learning rate를 줄이는 방법으로 학습을 더 효율적으로 할 수 있다. (Learning Rate Decay)\n",
    "![hyperparameter_2.png](images/hyperparameter_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatch Size\n",
    "\n",
    "batch size는 보통 2의 배수로 하는 것이 일반적이다. (2, 4, 8, 16, 32, 64, 128, 256) - '32, 64, 128, 256' 이 가장 흔하다.    \n",
    "너무 작으면 너무 느려지고, 너무 많으면 학습이 제대로 되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Hidden Units / Layers\n",
    "\n",
    "너무 많은 히든 레이어를 추가하면 오버피팅 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Hyperparameters\n",
    "\n",
    "LSTM과 GRU를 선택. 상황마다 최적의 모델이 달라진다.    \n",
    "![hyperparameter_3.png](images/hyperparameter_3.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
