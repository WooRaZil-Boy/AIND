{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Modeling\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model\n",
    "\n",
    "![image_1.png](images/nlp-m1-l4-language-model.002.png)\n",
    "\n",
    "언어 모델은 단어의 분포 통계에서 부터 시작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'again': 1, 'dumpty': 1, 'humpy': 1, 'together': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = ['humpy', 'dumpty', 'together', 'again']\n",
    "counts = Counter(words) # counter를 사용해서, 각 단어의 수를 셀 수 있다.\n",
    "# 그 후 카운터를 총 단어 수로 나누면 0 ~ 1 사이의 범위로 정규화할 수 있다. 즉 확률로 나타낼 수 있다.\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_2.png](images/nlp-m1-l4-language-model.005.png)\n",
    "\n",
    "확률 분포이기 때문에, 이를 활용해서 새로운 텍스트를 생성할 수 있다.    \n",
    "코퍼스의 단어 비율을 반영한다. 하지만 다른 것은 전혀 반영되지 않았기에 모델을 발전 시켜야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['humpy',\n",
       " 'again',\n",
       " 'again',\n",
       " 'again',\n",
       " 'humpy',\n",
       " 'dumpty',\n",
       " 'together',\n",
       " 'humpy',\n",
       " 'again',\n",
       " 'dumpty']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "words = random.choices(list(counts.keys()), weights=list(counts.values()), k=10)\n",
    "#카운터의 키로 10개의 요소를 가진 리스트를 만든다. 랜덤 선택의 가중치는 카운터의 value(등장 빈도)를 따른다.\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_3.png](images/nlp-m1-l4-language-model.006.png)\n",
    "\n",
    "단순히 단어 비율을 반영한 것은 의미가 없다. 단어끼리의 컨텍스트가 중요하다.    \n",
    "각 단어로 행렬을 만들어, 컨텍스트를 표현해 줄 수 있다. 셀(i, j)는 단어 i가 발생할 때마다 단어 j가 바로 뒤 따를 확률을 나타낸다.    \n",
    "이후 조건부 확률로 정규화한다.\n",
    "\n",
    "하지만 행렬이 커지만 메모리 사용량도 매우 커지기 때문에, dictionary로 count를 직접 넣어줘서 모델을 만들 수 있다.\n",
    "\n",
    "```\n",
    "{\n",
    "    'humpty': {'dumpty': 2, 'together': 1},\n",
    "    'dumpty': {'had': 1, 'sat': 1},\n",
    "    'all': {'the': 2},\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('humpy', 'again'),\n",
       " ('again', 'again'),\n",
       " ('again', 'again'),\n",
       " ('again', 'humpy'),\n",
       " ('humpy', 'dumpty'),\n",
       " ('dumpty', 'together'),\n",
       " ('together', 'humpy'),\n",
       " ('humpy', 'again'),\n",
       " ('again', 'dumpty')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [(words[i], words[i + 1]) for i in range(len(words) - 1)]\n",
    "#연속된 단어 쌍을 찾아 리스트로 저정한다.\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_4.png](images/nlp-m1-l4-language-model.007.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
